{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "atari_pooyan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raynardj/python4ml/blob/master/experiments/rl/atari_pooyan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ELevFSo1dESs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pooyan with DQN"
      ]
    },
    {
      "metadata": {
        "id": "pDbCPNezeM39",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4RuxLzreJBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install modules"
      ]
    },
    {
      "metadata": {
        "id": "AKSD5reSdRPP",
        "colab_type": "code",
        "outputId": "d6ccf7fe-ae31-41b7-9624-98da7b910333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "!pip install gym\n",
        "!pip install gym[atari]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.2 [783 kB]\n",
            "Fetched 783 kB in 7s (119 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 130812 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.2_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/39/37/f285403a09cc261c56b6574baace1bdcf4b8c7428c8a7239cbba137bc0eb/PyVirtualDisplay-0.2.1.tar.gz\n",
            "Collecting EasyProcess (from pyvirtualdisplay)\n",
            "  Downloading https://files.pythonhosted.org/packages/45/3a/4eecc0c7995a13a64739bbedc0d3691fc574245b7e79cff81905aa0c2b38/EasyProcess-0.2.5.tar.gz\n",
            "Building wheels for collected packages: pyvirtualdisplay, EasyProcess\n",
            "  Building wheel for pyvirtualdisplay (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8c/16/1c64227974ae29c687e4cc30fd691d5c0fd40f54446dde99da\n",
            "  Building wheel for EasyProcess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/22/19/af15ef6264c58b625a82641ed7483ad05e258fbd8925505227\n",
            "Successfully built pyvirtualdisplay EasyProcess\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.5 pyvirtualdisplay-0.2.1\n",
            "Collecting piglet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f6/ef278239ebe525466ea51a7dd9d6d3211d197ac4b4abc76e17cdd419f69c/piglet-0.4.4.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hCollecting Parsley (from piglet)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet) (19.1.0)\n",
            "Collecting astunparse (from piglet)\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/37/5dd0dd89b87bb5f0f32a7e775458412c52d78f230ab8d0c65df6aabc4479/astunparse-1.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet) (1.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (0.33.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (1.12.0)\n",
            "Building wheels for collected packages: piglet\n",
            "  Building wheel for piglet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/59/a5/5bd1a35a4a4596714c4c7925a1751e7b1580b6ced363fd7969\n",
            "Successfully built piglet\n",
            "Installing collected packages: Parsley, astunparse, piglet\n",
            "Successfully installed Parsley-1.3 astunparse-1.6.2 piglet-0.4.4\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.16.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.16.3)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.2.1)\n",
            "Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (3.1.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.3.0)\n",
            "Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.1.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (3.0.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8LKQuiVeRS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries and modules"
      ]
    },
    {
      "metadata": {
        "id": "f9DdvBPJeXMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4d-S2Ckf9em",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up environment"
      ]
    },
    {
      "metadata": {
        "id": "Npb7Jgroe8DF",
        "colab_type": "code",
        "outputId": "6b63b323-970a-449e-d28b-14ba8dadea6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Pooyan-v0\").unwrapped\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipy = 'inline' in matplotlib.get_backend()\n",
        "if is_ipy:\n",
        "    from IPython import display\n",
        "    \n",
        "plt.ion()\n",
        "\n",
        "# if GPU is used\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"We are using IPython\", is_ipy)\n",
        "print(\"We are on device\", dev)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are using IPython True\n",
            "We are on device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tDMm_my4fdFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Replay Memory"
      ]
    },
    {
      "metadata": {
        "id": "Zt_pNM0qg0i_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Transition = namedtuple(\"Transition\",\n",
        "                        (\"state\",\"action\",\"next_state\",\"reward\"))\n",
        "\n",
        "class Replay_Memory(object):\n",
        "    def __init__(self,capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        \n",
        "    def push(self,*args):\n",
        "        \"\"\"\n",
        "        args: in order: state, action, next_state, reward\n",
        "        \"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position+1) % self.capacity\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6se8Dt7qwk5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DQN Algorithm"
      ]
    },
    {
      "metadata": {
        "id": "q_h7Kgv6q43v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, action_space = 2, flatten = 512):\n",
        "        super(DQN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,16,kernel_size=5,stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16,32, kernel_size=5,stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32,32, kernel_size=5,stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.conv4 = nn.Conv2d(32,64, kernel_size=5,stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(64,64, kernel_size=5,stride=2)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        self.head = nn.Sequential(*[\n",
        "            nn.Linear(flatten, flatten, ), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(flatten, action_space),\n",
        "                                   ])\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivdOLCVvBUmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing Forward Pass Shape\n",
        "# dqn = DQN()\n",
        "# dqn(torch.rand(1,3,250,160)).size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQBrWNTR56M5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Image Get & Transformation Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "B6NN6n2B4V-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resize = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((250,160),interpolation=Image.CUBIC),\n",
        "    T.ToTensor()\n",
        "                     ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XF7aeUlx6q1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_screen():\n",
        "    \"\"\"\n",
        "    screen,screen_arr = get_screen()\n",
        "    plt.imshow(screen_arr)\n",
        "    return: Image Tensor(BCHW), numpy.array(HWC)\n",
        "    \"\"\"\n",
        "    raw_arr = env.render(mode = \"rgb_array\")\n",
        "    arr = raw_arr.transpose(2,0,1) # 3,250,160\n",
        "    # strip off unnecessary\n",
        "    screen = torch.from_numpy(raw_arr)\n",
        "    return screen.unsqueeze(0).to(dev), raw_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "srl6TTQ29qST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "screen,screen_arr = get_screen()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APP6UDak-eHL",
        "colab_type": "code",
        "outputId": "5ed9324c-0794-4e17-dff6-c94b93989cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(screen_arr)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e326bfc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAD8CAYAAAA18TUwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny+G2tBxuS8vhtrQcbkvr/wFTyq+UjJnSmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lBVi8yvR-oiV",
        "colab_type": "code",
        "outputId": "85a02ba3-be0b-4564-c1bf-47c6577660ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(env.reset())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3cb0401f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAD8CAYAAAA18TUwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny+G2tBxuS8vhtrQcbkvr/wFTyq+UjJnSmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_VtxlpvF_n6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "ZYb7Q1YRAx2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configs\n",
        "\n",
        "BS = 128\n",
        "GAMMA = .999\n",
        "\n",
        "EPS_START = .9\n",
        "EPS_END = .05\n",
        "DECAY = 2000\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "ACTION_SPACE = env.action_space.n\n",
        "\n",
        "# Initialize\n",
        "\n",
        "policy_net = DQN().to(dev)\n",
        "target_net = DQN().to(dev)\n",
        "\n",
        "def sync(p,t):\n",
        "    \"\"\"\n",
        "    target_net = sync(policy_net,target_net)\n",
        "    \"\"\"\n",
        "    t.load_state_dict(p.state_dict())\n",
        "    t.eval()\n",
        "    return t\n",
        "\n",
        "target_net = sync(policy_net, target_net)\n",
        "\n",
        "opt = optim.RMSprop(policy_net.parameters())\n",
        "memory = Replay_Memory(int(1e4))\n",
        "\n",
        "steps_done = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYVV3aFsBtMg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def select_action(state):\n",
        "    \"\"\"\n",
        "    Choose an action from state\n",
        "    But with some chances, choose randomly\n",
        "    \"\"\"\n",
        "    global steps_done\n",
        "    sample = random.sample()\n",
        "    eps_threshold = EPS_END+(EPS_START - EPS_END) * math.exp(-1. * steps_done/DECAY)\n",
        "    steps_don+=1\n",
        "    if sample > eps_threshold:\n",
        "        # choose according to policy\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(dim = 1)[1].view(1,1)\n",
        "    else:\n",
        "        # choose randomly\n",
        "        return torch.tensor([[random.randrange(ACTION_SPACE)]], device=dev, dtype = torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuGN2JKhrurp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ]
    },
    {
      "metadata": {
        "id": "5QVOruFMtpbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize():\n",
        "    \"\"\"\n",
        "    optimize step, \n",
        "    return: loss value\n",
        "    \"\"\"\n",
        "    if len(memory) < BS:\n",
        "        # do nothing when didn't play enough game\n",
        "        return {\"loss\":0.}\n",
        "    transitions = memory.sample(BS)\n",
        "    \n",
        "    batch = Transition(zip(*transitions))\n",
        "    \n",
        "    none_final_mask = torch.tensor(list(map(lambda s: s != None, batch.next_state)),\n",
        "                                   device=dev, dtype = torch.unit8)\n",
        "    none_final_next = torch.cat(list(s for s in batch.next_state if s != None))\n",
        "    \n",
        "    state_batch = torch.cat(batch.state, dim=0)\n",
        "    action_batch = torch.cat(batch.action, dim=0)\n",
        "    reward_batch = troch.cat(batch.reward, dim=0)\n",
        "    \n",
        "    # Compute Q(s_t,a)\n",
        "    # * The model computes Q(s_t)\n",
        "    # * Use .gather to choose the state value by action taken\n",
        "    state_action_values = policy_net(state_batch).gather(1,action_batch)\n",
        "    \n",
        "    # Compute V(s_{t+1}) for all next states, left part of the loss\n",
        "    next_state_values = torch.zeros(BS,device=dev)\n",
        "    next_state_values[none_final_max] = policy_net(non_final_next).max(dim=1)[0].detach()\n",
        "    \n",
        "    expected_state_action_values = (next_state_values * GAMMA) + batch_reward\n",
        "    \n",
        "    # Compute Huber Loss, right part of the loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, \n",
        "                            expected_state_action_values.unsqueeze(1))\n",
        "    \n",
        "    # Optimize the model\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    \n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1,1)\n",
        "    \n",
        "    opt.step()\n",
        "    \n",
        "    return {\"loss\":loss.item()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8l8dAq2Lu1d7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}